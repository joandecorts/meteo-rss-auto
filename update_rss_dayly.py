import requests
from bs4 import BeautifulSoup
from datetime import datetime
import pytz
import json
import os

def write_log(message):
    print(message)
    with open('debug_dayly.log', 'a', encoding='utf-8') as f:
        f.write(message + '\n')

def get_daily_summary_from_meteocat(station_code, station_name):
    """ObtÃ© el resum diari REAL de MeteoCat (no acumulaciÃ³ local)"""
    try:
        today = datetime.now().strftime("%Y-%m-%d")
        url = f"https://www.meteo.cat/observacions/xema/dades?codi={station_code}&dia={today}"
        
        write_log(f"ğŸŒ Consultant resum diari REAL: {station_name} [{station_code}]")
        write_log(f"   URL: {url}")
        
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Buscar totes les taules
        tables = soup.find_all('table')
        
        for i, table in enumerate(tables):
            # Verificar si aquesta taula contÃ© "Resum diari" o "Temperatura"
            table_text = table.get_text()
            if 'Resum diari' in table_text or 'Temperatura' in table_text:
                write_log(f"ğŸ“Š Taula {i} sembla contenir dades del dia")
                
                # Buscar totes les files de la taula
                rows = table.find_all('tr')
                
                # Diccionari per emmagatzemar valors trobats
                valors = {}
                
                for row in rows:
                    cells = row.find_all(['td', 'th'])
                    if len(cells) >= 2:
                        label = cells[0].get_text(strip=True)
                        valor = cells[1].get_text(strip=True)
                        
                        # Identificar valors clau
                        if 'Temperatura mitjana' in label or 'Temperatura mÃ¡xima' in label or 'Temperatura mÃ­nima' in label or 'PrecipitaciÃ³ acumulada' in label:
                            # Extreure nÃºmero del valor
                            import re
                            num_match = re.search(r'([-]?\d+[.,]?\d*)', valor)
                            if num_match:
                                num = float(num_match.group(1).replace(',', '.'))
                                valors[label] = num
                                write_log(f"   âœ… {label}: {num}")
                
                # Retornar els valors trobats
                if valors:
                    return {
                        'data': today,
                        'estacio': station_code,
                        'nom_estacio': station_name,
                        'temp_mitjana': valors.get('Temperatura mitjana'),
                        'temp_maxima': valors.get('Temperatura mÃ¡xima'),
                        'temp_minima': valors.get('Temperatura mÃ­nima'),
                        'pluja_acumulada': valors.get('PrecipitaciÃ³ acumulada')
                    }
        
        # Si no trobem la taula, provem amb una cerca mÃ©s agressiva
        write_log("âš ï¸ No s'ha trobat la taula amb el patrÃ³ esperat, provant cerca alternativa...")
        
        # Cerca per tots els texts que continguin nÃºmeros i paraules clau
        all_text = soup.get_text()
        import re
        
        # Patrons per a temperatures
        temp_max_pattern = r'Temperatura mÃ¡xima[:\s]*([-]?\d+[.,]?\d*)'
        temp_min_pattern = r'Temperatura mÃ­nima[:\s]*([-]?\d+[.,]?\d*)'
        pluja_pattern = r'PrecipitaciÃ³ acumulada[:\s]*([-]?\d+[.,]?\d*)'
        
        temp_max_match = re.search(temp_max_pattern, all_text)
        temp_min_match = re.search(temp_min_pattern, all_text)
        pluja_match = re.search(pluja_pattern, all_text)
        
        resultat = {
            'data': today,
            'estacio': station_code,
            'nom_estacio': station_name,
            'temp_maxima': float(temp_max_match.group(1).replace(',', '.')) if temp_max_match else None,
            'temp_minima': float(temp_min_match.group(1).replace(',', '.')) if temp_min_match else None,
            'pluja_acumulada': float(pluja_match.group(1).replace(',', '.')) if pluja_match else None
        }
        
        if resultat['temp_maxima']:
            write_log(f"   âœ… Temperatura mÃ¡xima (alternativa): {resultat['temp_maxima']}")
        if resultat['temp_minima']:
            write_log(f"   âœ… Temperatura mÃ­nima (alternativa): {resultat['temp_minima']}")
        if resultat['pluja_acumulada'] is not None:
            write_log(f"   âœ… PrecipitaciÃ³ acumulada (alternativa): {resultat['pluja_acumulada']}")
        
        return resultat
        
    except Exception as e:
        write_log(f"âŒ Error consultant resum diari: {e}")
        return None

def save_daily_summary(summary_data):
    """Guarda el resum diari a daily_summary.json"""
    try:
        # Llegir dades existents
        if os.path.exists('daily_summary.json'):
            with open('daily_summary.json', 'r', encoding='utf-8') as f:
                all_data = json.load(f)
        else:
            all_data = {}
        
        # Actualitzar amb les dades noves
        data_key = summary_data['data']
        
        if data_key not in all_data:
            all_data[data_key] = {}
        
        station_code = summary_data['estacio']
        all_data[data_key][station_code] = {
            'station_name': summary_data['nom_estacio'],
            'temp_maxima': summary_data['temp_maxima'],
            'temp_minima': summary_data['temp_minima'],
            'pluja_acumulada': summary_data['pluja_acumulada'],
            'actualitzat': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
        # Guardar
        with open('daily_summary.json', 'w', encoding='utf-8') as f:
            json.dump(all_data, f, ensure_ascii=False, indent=2)
        
        write_log(f"ğŸ’¾ Resum diari guardat a daily_summary.json")
        return True
        
    except Exception as e:
        write_log(f"âŒ Error guardant resum diari: {e}")
        return False

def generar_rss_diari():
    write_log("\nğŸš€ GENERANT RSS DIARI (RESUMS REALS)")
    
    cet = pytz.timezone('CET')
    now = datetime.now(cet)
    data_avui = now.strftime('%Y-%m-%d')
    
    estacions = [
        {"code": "XJ", "name": "Girona"},
        {"code": "UO", "name": "Fornells de la Selva"}
    ]
    
    entrades = []
    resums_trobats = []
    
    for station in estacions:
        write_log(f"\nğŸ“Š Consultant resum REAL per {station['name']}")
        
        # Obtenir resum REAL de MeteoCat
        resum = get_daily_summary_from_meteocat(station['code'], station['name'])
        
        if resum and resum.get('temp_maxima') is not None:
            # Guardar a daily_summary.json
            save_daily_summary(resum)
            resums_trobats.append(resum)
            
            # Preparar dades per RSS
            temp_max = resum['temp_maxima']
            temp_min = resum['temp_minima']
            pluja = resum['pluja_acumulada'] if resum['pluja_acumulada'] is not None else 0.0
            
            # VERSIÃ“ CATALÃ€ - RESUM DIARI REAL
            titol_cat = f"ğŸ“Š RESUM DEL DIA {station['name']} | Data: {data_avui} | PerÃ­ode: 00:00-24:00 | ğŸ”¥ Temperatura MÃ xima: {temp_max}Â°C | â„ï¸ Temperatura MÃ­nima: {temp_min}Â°C | ğŸŒ§ï¸ Pluja Acumulada: {pluja}mm"
            
            # VERSIÃ“ ANGLÃˆS - RESUM DIARI REAL
            titol_en = f"ğŸ“Š TODAY'S SUMMARY {station['name']} | Date: {data_avui} | Period: 00:00-24:00 | ğŸ”¥ Maximum Temperature: {temp_max}Â°C | â„ï¸ Minimum Temperature: {temp_min}Â°C | ğŸŒ§ï¸ Accumulated Rain: {pluja}mm"
            
            titol = f"{titol_cat} || {titol_en}"
            
            # URL per al resum diari
            link_resum = f"https://www.meteo.cat/observacions/xema/dades?codi={station['code']}&dia={data_avui}"
            
            entrada = f'''  <item>
    <title>{titol}</title>
    <link>{link_resum}</link>
    <description>Resum diari de {station['name']} - Data: {data_avui} - Actualitzat a les {now.strftime('%H:%M')} CET / Daily summary from {station['name']} - Date: {data_avui} - Updated at {now.strftime('%H:%M')} CET</description>
    <pubDate>{now.strftime("%a, %d %b %Y %H:%M:%S CET")}</pubDate>
  </item>'''
            
            entrades.append(entrada)
            write_log(f"âœ… Resum REAL generat: MÃ x={temp_max}Â°C, MÃ­n={temp_min}Â°C, Pluja={pluja}mm")
        else:
            write_log(f"âš ï¸ No s'han pogut obtenir dades del dia per {station['name']}")
            
            # Fallback: llegir del daily_summary.json si existeix
            if os.path.exists('daily_summary.json'):
                try:
                    with open('daily_summary.json', 'r', encoding='utf-8') as f:
                        all_data = json.load(f)
                    
                    if data_avui in all_data and station['code'] in all_data[data_avui]:
                        dades = all_data[data_avui][station['code']]
                        
                        titol_cat = f"ğŸ“Š RESUM DEL DIA {station['name']} | Data: {data_avui} | ğŸ”¥ Temperatura MÃ xima: {dades['temp_maxima']}Â°C | â„ï¸ Temperatura MÃ­nima: {dades['temp_minima']}Â°C | ğŸŒ§ï¸ Pluja Acumulada: {dades['pluja_acumulada']}mm"
                        titol_en = f"ğŸ“Š TODAY'S SUMMARY {station['name']} | Date: {data_avui} | ğŸ”¥ Maximum Temperature: {dades['temp_maxima']}Â°C | â„ï¸ Minimum Temperature: {dades['temp_minima']}Â°C | ğŸŒ§ï¸ Accumulated Rain: {dades['pluja_acumulada']}mm"
                        titol = f"{titol_cat} || {titol_en}"
                        
                        link_resum = f"https://www.meteo.cat/observacions/xema/dades?codi={station['code']}&dia={data_avui}"
                        
                        entrada = f'''  <item>
    <title>{titol}</title>
    <link>{link_resum}</link>
    <description>Resum diari de {station['name']} - Data: {data_avui} - Actualitzat a les {dades['actualitzat']} CET / Daily summary from {station['name']} - Date: {data_avui} - Updated at {dades['actualitzat']} CET</description>
    <pubDate>{now.strftime("%a, %d %b %Y %H:%M:%S CET")}</pubDate>
  </item>'''
                        
                        entrades.append(entrada)
                        write_log(f"âœ… Resum de cÃ²pia de seguretat generat")
                except Exception as e:
                    write_log(f"âš ï¸ Error llegint cÃ²pia de seguretat: {e}")
    
    rss_content = f'''<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
<channel>
  <title>MeteoCat Resums Diaris Reals</title>
  <link>https://www.meteo.cat</link>
  <description>Resums meteorolÃ²gics reals del dia actual - Estacions Girona i Fornells de la Selva / Today's real weather summaries - Girona and Fornells de la Selva stations</description>
  <lastBuildDate>{now.strftime("%a, %d %b %Y %H:%M:%S CET")}</lastBuildDate>
{chr(10).join(entrades)}
</channel>
</rss>'''
    
    try:
        with open('update_meteo_dayly.rss', 'w', encoding='utf-8') as f:
            f.write(rss_content)
        write_log("âœ… RSS diari (resums reals) generat correctament")
        write_log(f"ğŸ“ Arxiu: update_meteo_dayly.rss")
        return True
    except Exception as e:
        write_log(f"âŒ Error guardant RSS diari: {e}")
        return False

if __name__ == "__main__":
    with open('debug_dayly.log', 'w', encoding='utf-8') as f:
        f.write(f"=== INICI RSS DIARI: {datetime.now()} ===\n")
    
    write_log("ğŸš€ Script de resums diaris reals")
    
    try:
        exit = generar_rss_diari()
        if exit:
            write_log("ğŸ‰ Ãˆxit complet - RSS diari amb dades reals generat")
        else:
            write_log("ğŸ’¤ Fallada en la generaciÃ³ del RSS diari")
    except Exception as e:
        write_log(f"ğŸ’¥ ERROR: {e}")
        import traceback
        write_log(f"ğŸ“‹ Traceback: {traceback.format_exc()}")
        exit = False
    
    write_log(f"=== FI RSS DIARI: {datetime.now()} ===")
